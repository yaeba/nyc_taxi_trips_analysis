---
title: "MAST30034 Assignment 1"
author: "Xuanken Tay"
date: "August 6, 2019"
output: 
  html_document:
    number_sections: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: readable
    highlights: tango
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

This is an introduction. **Bold**. *Italic*, `command`

## New York City Taxi & Limousine Commission (TLC) Service Trip Record Data

## TLC Taxi Zone Data

- [Taxi Zone Lookup Table](https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv): a lookup table that contains TLC taxi zone location IDs, location names and corresponding boroughs for each ID is used to convert ...  

- [Taxi Zone Shapefile](https://s3.amazonaws.com/nyc-tlc/misc/taxi_zones.zip): a shapefile containing the boundaries for the taxi zones for use in geospatial visualisation.  

## New York Central Park Weather Data

Central Park weather data comes from [National Climatic Data Center](https://www.ncdc.noaa.gov/). Contains daily weather observation. Columns are [average daily wind speed(mile/hr), precipitation(inch), snowfall (inch), snow depth (inch), maximum temperature (fahrenheit), minimum temperature (fahrenheit]


## Another external data


## Load libraries and helper functionsz

Put all libraries and descrpitions here

```{r libraries, message=FALSE}
library(tidyverse)
library(data.table)
library(ggmap)
library(tmap)
library(rgdal)
library(lubridate)
```

Functions 

```{r helper_funcs}
read_taxi_data <- function(months, cols) {
  dfs <- list()
  for (i in sprintf("%02d", months)) {
    fname <- paste0("data/green_tripdata_2015-", i, ".csv.gz")
    dfs[[i]] <- fread(fname, fill=TRUE, select=cols, showProgress=FALSE)
  }
  rbindlist(dfs)
}

restart_r <- function() {
  rm(list=ls())
  .rs.restartR()
}

m <- function() pryr::mem_used()

```

*multiplot* function, courtesy of [R Cookbooks](http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/) to create multi-panel plots.

```{r multiplot}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

----------------------------------------------------------------------------------------------------------

# Data Selection

Green taxi data has been chosen for this analysis. Because ... and less space on disk.

## Period Selection

I selected data from month.... because ... (summer and winter)
```{r}
year <- 2015
summer_months <- c(6, 7, 8)
winter_months <- c(12, 1, 2)

#summer_months <- c(7)
#winter_months <- c(1)
```

## Attribute Selection

Attributes ... have been chosen for analysis.

```{r}
cols_selected <- c("lpep_pickup_datetime", "Lpep_dropoff_datetime",
                   "Trip_distance", "Tip_amount", "Total_amount",
                   "Passenger_count", "Payment_type", 
                   "Pickup_latitude", "Pickup_longitude",
                   "Dropoff_latitude", "Dropoff_longitude")
```


----------------------------------------------------------------------------------------------------------

# Data Preparation

The NYC taxi trip data has been processed minimally from the shell. The only alteration done on the data with unix was just compressing it to gzipped format. This step was performed to reduce the disk space required to hold the data.  

The summer and winter data were then read into R separately. Thanks to "data.table" package, reading and subsequent binding of datasets can be done faster and more efficiently.
```{r summer_and_winter, message=FALSE}
summer_trips <- read_taxi_data(summer_months, cols_selected)
winter_trips <- read_taxi_data(winter_months, cols_selected)

cat(paste0("Number of records in summer data: ", dim(summer_trips)[1],
           "\n",
            "Number of records in winter data: ", dim(winter_trips)[1])
)
```

The trips data were then merged together to give us a dataframe to work on for the analysis. An extra attribute that captures the duration of all trips could also be added to the data by computing the time difference between pickup and dropoff as recorded by taximeter. Structure of the resultant merged dataframe (data.table) is shown below.

```{r merge_summer_winter}
# bind summer and winter data together
trips_data <- rbindlist(list(summer=summer_trips, winter=winter_trips),
                        idcol="Season")

# to save space
rm(summer_trips, winter_trips)

# convert to date objects and find difference
setnames(trips_data, 
         old=c("lpep_pickup_datetime", "Lpep_dropoff_datetime"),
         new=c("Pickup_datetime", "Dropoff_datetime"))
trips_data[, Pickup_datetime := ymd_hms(Pickup_datetime)]
trips_data[, Dropoff_datetime := ymd_hms(Dropoff_datetime)]
trips_data[, Trip_duration := difftime(Dropoff_datetime,
                                       Pickup_datetime,
                                       units="mins") %>% as.numeric() %>% round(digits=1)]

str(trips_data)
```

Taxi zones location and geospatial information were also read in to assist our analysis on the trips data.  

External data (weather), filter to months

```{r lookup_shapefile}
zones_lookup <- read_csv("data/taxi+_zone_lookup.csv", col_types="iccc")
taxi_zones <- readOGR(dsn = "data/taxi_zones/taxi_zones.shp", verbose=FALSE)

weather <- read_csv("data/central_park_weather.csv", col_types="ccDddddii") %>%
  filter(month(DATE) %in% c(summer_months, winter_months)) %>%
  mutate(AVG_T = (TMAX + TMIN) / 2) %>%
  select(-c("STATION", "NAME", "TMAX", "TMIN"))
```


Assuming the taxi trip data contains no duplicate records for any single trip, we can then continue with data cleansing and preprocessing. 

## Data Cleansing

It is important to clean the data as removing incorrect information can improve the data quality and in doing so, increases overal productivity. Note that here I cleaned only the taxi trip data as it is ultimately the one to be analysed. Any other data such as the zone information or weather data from external sources to aid in downstream analysis will be assumed to be clean.  

The trips data has been checked and none of rows - with chosen attributes contains missing value. It is great because we do not have to worry about losing useful data or doing missing value imputation.


```{r missing_val}
cat(paste(
  "Number of rows with missing value(s) in trips data:",
  sum(rowSums(is.na(trips_data)))
  )
)
```

Next the data was checked to remove any abnormal or wrong records. This step is important as it ensures the data is correct, consistent and useable by identifying any errors or inaccurate information in the data. Since manually correcting the data requires huge amount of time and relevant domain knowledge, I decided to simply remove trip records that contain any obvious errors.  

Along with some defined "errors", we also want to remove outliers in the data since they are so rare, uninteresting and may not contribute much to the downstream analysis. Briefly, dirtyness in the trips records have been checked and filtered out according to the follwing criteria:  
- $Passenger\_count = 0$ or $> 7$ (Number of passenger in the vehicle)  
- $Pickup/Dropoff\_latitude \notin (39, 42)$ or $Pickup/Dropoff\_longitutde \notin (-76, -72)$  
  * Pickup or dropoff outside of New York City, only trips within New York are of interest, exact location of New York is [40°39′40″N 73°56′38″W](https://en.wikipedia.org/wiki/New_York_City)  
- $Tip\_amount < 0$ or $> 200 dollars$  
- $Total\_amount <= 0$ or $> 300 dollars$  
- $Trip\_duration < 1 minute$ $> 12 hours$  
- $Trip\_distance <= 0$ or $> 100 miles$  
- $Payment\_type$ of neither credit card nor cash  

The thresholds have been chosen after conducting brief analysis on descriptive statistics on those variables.  
```{r data_cleaning}
n_before <- dim(trips_data)[1]

# do filtering
trips_data <- trips_data[
  !(Passenger_count == 0 | Passenger_count > 7 |
      Pickup_latitude < 39 | Pickup_latitude > 42 |
      Pickup_longitude < -76 | Pickup_longitude > -72 |
      Dropoff_latitude < 39 | Dropoff_latitude > 42 |
      Dropoff_longitude < -76 | Dropoff_longitude > -72 |
      Tip_amount < 0 | Tip_amount > 200 |
      Total_amount <= 0 | Total_amount > 300 |
      Trip_duration < 1 | Trip_duration > (12 * 60) |
      Trip_distance <= 0 | Trip_distance > 100 |
      Payment_type > 2),
]

n_after <- dim(trips_data)[1]

cat(paste(
  "Removed", n_before - n_after, "rows from the trips data")
)
```

Now the trips data has been cleaned, we are left with higher quality information, we can now continue with data preprocessing for the analysis.

## Data Preprocessing

Merge taxi_zones data with zones_lookup$Service zone.  Also find intersect between location points and taxi zones
```{r merge_intersect, warning=FALSE}
# merge zone information with taxi service zone in lookup table
taxi_zones@data <- taxi_zones@data %>%
  left_join(zones_lookup %>% 
              select(-LocationID, -Borough) %>%
              unique(), 
            by=c('zone' = 'Zone'))

# reproject to commonly used CRS
taxi_zones <- spTransform(taxi_zones, CRS("+init=epsg:4326"))

# find intersect between trip locations and taxi zones
trips_data[, 
  Pickup_location := SpatialPointsDataFrame(coords=trips_data[, c('Pickup_longitude', 'Pickup_latitude')],
                                            data=trips_data,
                                            proj4string=CRS(proj4string(taxi_zones))) %>%
    over(taxi_zones) %>%
    pull(OBJECTID)]

trips_data[, 
  Dropoff_location := SpatialPointsDataFrame(coords=trips_data[, c('Dropoff_longitude', 'Dropoff_latitude')],
                                             data=trips_data,
                                             proj4string=CRS(proj4string(taxi_zones))) %>%
    over(taxi_zones) %>%
    pull(OBJECTID)]


# some trips may not fall in known taxi zones
trips_data <- na.omit(trips_data)
```

We also need to preprocess datetime to extract day of week. Resultant of preprocessed dataframe is shown below
```{r preprocess_date}
trips_data[, Pickup_day := wday(Pickup_datetime, label=TRUE)]
trips_data[, Pickup_hour := hour(Pickup_datetime)]
trips_data[, Dropoff_day := wday(Dropoff_datetime, label=TRUE)]
trips_data[, Dropoff_hour := hour(Dropoff_datetime)]
trips_data[, Pickup_datetime := as_date(Pickup_datetime)]
trips_data[, Dropoff_datetime := as_date(Dropoff_datetime)]

setnames(trips_data, 
         old=c("Pickup_datetime", "Dropoff_datetime"),
         new=c("Pickup_date", "Dropoff_date"))

trips_data <- as_tibble(trips_data)
glimpse(trips_data)
```

```{r}
# saveRDS(trips_data, file="data/trips_data.rds")
trips_data <- readRDS("data/trips_data.rds")
```


----------------------------------------------------------------------------------------------------------

# Findings and Analysis


## What affects tipping
```{r tipping}


# Trip distance vs Tipping
n <- 100
trips_data %>%
  filter(Payment_type == 1) %>%
  mutate(Bin = cut_number(Trip_distance, n)) %>%
  group_by(Bin) %>%
  summarise(Trip_distance = mean(Trip_distance),
            Number = n(),
            Tip_amount = mean(Tip_amount),
            Total_amount = mean(Total_amount),
            Tipping_percentage = mean(Tip_amount / Total_amount),
            Trip_duration = mean(Trip_duration)) %>%
  ungroup() %>%
  gather(Tip_amount:Trip_duration, key="Measure", value="Value") %>%
  ggplot(aes(x=Trip_distance, y=Value, color=Number)) +
  geom_point() +
  facet_wrap(Measure ~ ., scales="free_y") +
  theme_bw()
  



# Time and day vs Tipping percentage
trips_data %>%
  filter(Payment_type == 1) %>%
  group_by(Season, Pickup_day, Pickup_hour) %>%
  summarise(Tipping_percentage = mean(Tip_amount / Total_amount)) %>%
  ggplot(aes(x=Pickup_day, y=Pickup_hour, fill=Tipping_percentage)) +
  geom_tile() +
  scale_fill_distiller(palette="Spectral") +
  scale_y_continuous(breaks=seq(0, 23)) +
  facet_grid(. ~ Season) +
  theme_bw() +
  labs(x="Day of the week", y="Hour of the day",
       title="Tipping percentage at different times of days")

#taxi_zones@data <- taxi_zones@data %>% select(-c(Tipping_percentage))
# Boroughs with pickups with most tipping percentage
taxi_zones@data <- taxi_zones@data %>%
  left_join(
    trips_data %>%
      group_by(Pickup_location) %>%
      summarise(Tipping_percentage = mean(Tip_amount / Total_amount)),
    by=c("OBJECTID"="Pickup_location"))

qtm(shp=taxi_zones, fill = "Tipping_percentage", fill.palette = "Blues") +
  tm_legend(main.title = "Ratio of tips to total amount for each pickup taxi zone",
            main.title.size = 1)
```
Zones with highest tipping percentage
1                      Hudson Sq          0.2603203
2         Charleston/Tottenville          0.2258583
3 Stuy Town/Peter Cooper Village          0.2000000
4                  Arden Heights          0.1999171

## What affects usage of taxi

```{r taxi_usage}
trips_data <- trips_data %>%
  mutate(Time=ifelse(Pickup_hour >=6 & Pickup_hour < 18,
                     "Daytime",
                     "Nighttime"))

# Day trip and night trip
trips_data %>%
  group_by(Season, Pickup_day, Time) %>%
  summarise(Num_trips = n()) %>%
  ungroup() %>%
  ggplot(aes(x=Pickup_day, y=Num_trips, fill=Time)) +
  geom_bar(stat="identity", position=position_dodge(), colour="black") +
  facet_grid(. ~ Season) +
  theme_bw() +
  labs(x="Day of the week", y="Number of taxi trips",
       title="Taxi pickups in daytime and nighttime across days of week")

# Time and day
trips_data %>%
  group_by(Season, Pickup_day, Pickup_hour) %>%
  summarise(Num_trips = n()) %>%
  ungroup() %>%
  ggplot(aes(x=Pickup_day, y=Pickup_hour, fill=Num_trips)) +
  geom_tile() +
  scale_fill_distiller(palette="Spectral") +
  scale_y_continuous(breaks=seq(0, 23)) +
  facet_grid(. ~ Season) +
  theme_bw() +
  labs(x="Day of the week", y="Hour of the day",
       title="Taxi pickups at different times of days")


# How likely to get long trip in daytime and nighttime
long_trip <- as.numeric(quantile(trips_data$Trip_distance, 0.8))
trips_data %>%
  group_by(Pickup_day, Time) %>%
  summarise(Long_trips = mean(Trip_distance > long_trip)) %>%
  ungroup() %>%
  ggplot(aes(x=Pickup_day, y=Long_trips, fill=Time)) +
  geom_bar(stat="identity", position=position_dodge(), colour="black") +
  theme_bw() +
  labs(x="Day of the week", y="Probability of long trip",
       title=paste0("How likely to get a long trip (>", long_trip, " miles)"))


#taxi_zones@data <- taxi_zones@data %>% select(-c(Daytime, Nighttime))
# Boroughs with most trips in daytime and nighttime
taxi_zones@data <- taxi_zones@data %>%
  left_join(
    trips_data %>%
      group_by(Time, Pickup_location) %>%
      summarise(Num_trips = n()) %>%
      spread(key=Time, value=Num_trips),
    by=c("OBJECTID"="Pickup_location"))

qtm(shp=taxi_zones, fill = c("Daytime", "Nighttime"), fill.palette = "Blues", ncol = 2) +
  tm_legend(main.title = "Frequency of pickups in daytime and nighttime for each taxi zone",
            main.title.size = 1)

# Weather
trips_data %>%
  group_by(Season, Pickup_date) %>%
  summarise(Num_trips = n()) %>%
  ungroup() %>%
  left_join(weather, by=c("Pickup_date" = "DATE")) %>%
  gather(AWND:AVG_T, key="Measure", value="Value") %>%
  ggplot(aes(x=Value, y=Num_trips, color=Season)) +
  geom_point() +
  geom_smooth(method=lm) +
  facet_wrap(Measure ~ ., scales="free_x") +
  labs(x="Value of measurement", y="Frequency of pickups",
       title="Weather condition vs frequency of pickups of every day")


# Weather
trips_data %>%
  filter(Payment_type == 1) %>%
  group_by(Season, Pickup_date) %>%
  summarise(Tipping_percentage = mean(Tip_amount / Total_amount)) %>%
  ungroup() %>%
  left_join(weather, by=c("Pickup_date" = "DATE")) %>%
  gather(AWND:AVG_T, key="Measure", value="Value") %>%
  ggplot(aes(x=Value, y=Tipping_percentage, color=Season)) +
  geom_point() +
  geom_smooth(method=lm) +
  facet_wrap(Measure ~ ., scales="free_x")
```
Zones with most pickup in daytime:
1   East Harlem North  263803
2   East Harlem South  261508
3      Central Harlem  243942
4 Morningside Heights  193691

Zones with most pickup in nighttime:
1 Williamsburg (North Side)    340581
2                   Astoria    244592
3                  Elmhurst    217167
4            Central Harlem    207715

East Harlem South and Morningside Heights have more pickups in daytime than in nighttime.
Williamsbug North and South have more pickups in nighttime than in daytime.


## Weather and trip distance and duration


## Trip distance and tipping, weather and trip distance, weather and tipping, tipping and average speed
## What affects tipping behaviour of passenger



```{r}

```


## Usage of taxi at different days (leaflet?) at different boroughs, taxi pickup and dropoff at different location. taxi best tipping dropoff for every pickup

## Testing 
```{r}
library(rgdal)
lnd <- readOGR(dsn = "data/Creating-maps-in-R-master/data/london_sport.shp")
lnd$Pop_2001 <- as.numeric(as.character(lnd$Pop_2001))
```

```{r}
plot(lnd, col = "lightgrey") # plot the london_sport object
sel <- lnd$Partic_Per > 25
head(lnd@data)
plot(lnd[ sel, ], col = "turquoise", add = TRUE) # add selected zones to map
```


```{r}
crime_data <- read.csv("data/Creating-maps-in-R-master/data/mps-recordedcrime-borough.csv",
  stringsAsFactors = FALSE)

head(crime_data$CrimeType) # information about crime type

# Extract "Theft & Handling" crimes and save
crime_theft <- crime_data[crime_data$CrimeType == "Theft & Handling", ]
head(crime_theft, 2) # take a look at the result (replace 2 with 10 to see more rows)

# Calculate the sum of the crime count for each district, save result
crime_ag <- aggregate(CrimeCount ~ Borough, FUN = sum, data = crime_theft)
# Show the first two rows of the aggregated crime data
head(crime_ag, 2)
```

```{r}
library(dplyr)
lnd@data <- left_join(lnd@data, crime_ag, by = c('name' = 'Borough'))
head(lnd@data)
```

```{r}
library(tmap) # load tmap package (see Section IV)
qtm(lnd, "CrimeCount") # plot the basic map
```

```{r}
stations <- readOGR(dsn = "data/Creating-maps-in-R-master/data/lnd-stns.shp")
proj4string(stations)
proj4string(lnd)
bbox(stations) # the extent, 'bounding box' of stations
bbox(lnd) # return the bounding box of the lnd object
```

```{r}
stations <- spTransform(stations, CRSobj = CRS(proj4string(lnd)))
plot(lnd) # plot London 
points(stations) # overlay the station points

stations <- stations[lnd,]
plot(stations)
```

```{r}
library(tmap)
vignette("tmap-nutshell")

qtm(shp = lnd, fill = c("Partic_Per", "Pop_2001"), fill.palette = "Blues", ncol = 2)
```


```{r}
tm_shape(lnd) +
  tm_fill("Pop_2001", thres.poly = 0) +
  tm_facets("name", free.coords = TRUE, drop.units = TRUE)
```

```{r}
lnd_f <- broom::tidy(lnd)
head(lnd_f, n = 2) # peak at the fortified data
lnd$id <- row.names(lnd) # allocate an id variable to the sp data
head(lnd@data, n = 2) # final check before join (requires shared variable name)
lnd_f <- left_join(lnd_f, lnd@data) # join the data
head(lnd_f, 2)
```

```{r}
library(ggplot2)
ggplot(lnd_f, aes(long, lat, group = group, fill = Partic_Per)) +
  geom_polygon() + coord_equal() +
  labs(x = "Easting (m)", y = "Northing (m)",
    fill = "% Sports\nParticipation") +
  ggtitle("London Sports Participation") +
  scale_fill_gradient(low = "white", high = "black")
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
